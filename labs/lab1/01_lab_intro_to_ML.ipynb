{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from IPython.display import Image\n",
    "from IPython.core.display import HTML \n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wstęp do machine learningu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div>\n",
    "<img src=\"http://ema.drwhy.ai/figure/MDP_washmachine.png\" width=\"500\" style=\"float:middle\"/>\n",
    "</div>\n",
    "\n",
    "Narzędzia do tworzenia modeli ML:\n",
    "- R: dużo różnych pakietów, ale istnieją frameworki, które ujednolocają interfejs: [mlr3](https://mlr3.mlr-org.com/), [tidymodels](https://www.tidymodels.org/)\n",
    "- Python: biblioteka [sklearn](https://scikit-learn.org/stable/supervised_learning.html) (dla modeli klasycznych), Keras, PyTorch dla modeli głębokich"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Supervised learning\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regresja - regression\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Zmienna odpowiedzi ma charakter ciągły, może przyjmować wartość liczbową: rzeczywiste lub naturalne ($y \\in \\mathbf{R}$).\n",
    "\n",
    "Przykłady:\n",
    "- predykcja ceny mieszkania\n",
    "- predykcja wzrostu osób\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "diabetes, diabetes_y = datasets.load_diabetes(return_X_y=True, as_frame=True)\n",
    "diabetes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(diabetes_y,bins = 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Klasyikacja binarna - classification\n",
    "\n",
    "\n",
    "W przypadku klasyfikacji binarnej zmienna odpowiedzi może przyjmować dwie wartości, $y \\in \\{0,1\\}$.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "breast_cancer, breast_cancer_y = datasets.load_breast_cancer(return_X_y=True, as_frame=True)\n",
    "breast_cancer.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(breast_cancer_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Klasyfikacja wieloetykietowa\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris, iris_y = datasets.load_iris(return_X_y=True, as_frame=True)\n",
    "iris.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## unikalne zmiennej Y\n",
    "iris_y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(iris_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ten krok ma na celu poznanie zależności pomiędzy zmiennymi objaśniającymi i zmienną objaśnianą, a także pomiędzy zmiennymi objaśniającymi.\n",
    "\n",
    "ZADANIE \n",
    "\n",
    "Wymień możliwe operacje:\n",
    "- ...\n",
    "- ...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X, y = np.arange(10).reshape((5, 2)), range(5)\n",
    "print('X: \\n', X)\n",
    "\n",
    "print('y: ', list(y))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "print('X train: \\n', X_train, '\\n y train:', y_train)\n",
    "print('X test: \\n', X_test, '\\n y train:', y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## podział zbioru do regresji i klasyfikacji\n",
    "diabetes_X_train, diabetes_X_test, diabetes_y_train, diabetes_y_test = train_test_split(diabetes, diabetes_y, test_size=0.33, random_state=42)\n",
    "print('Liczba obserwacji w zbiorze treningowym:', diabetes_X_train.shape[0])\n",
    "print('Liczba obserwacji w zbiorze testowym:', diabetes_X_test.shape[0])\n",
    "\n",
    "print('Liczba zmiennych w modelu:', diabetes_X_train.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cancer_X_train, cancer_X_test, cancer_y_train, cancer_y_test = train_test_split(breast_cancer, breast_cancer_y, test_size=0.33, random_state=42)\n",
    "print('Liczba obserwacji w zbiorze treningowym:', cancer_X_train.shape[0])\n",
    "print('Liczba obserwacji w zbiorze testowym:', cancer_X_test.shape[0])\n",
    "\n",
    "print('Liczba zmiennych w modelu:', cancer_X_train.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training ML models\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Algorytmy uczenia maszynowego znajdują zależności między zmiennymi objaśniającymi a zmienną objaśnianą, czyli pomiędzy `X` i `y`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Proces uczenia - metoda `fit(X, y)` :\n",
    "1. Znalezienie zależności pomiędzy zmiennymi a `y`. Postać tej zależności jest zadana przez rodzaj wybranego algorytmu.\n",
    "2. Algorytm ocenia jakość znalezionej zależności poprzez funkcję celu.\n",
    "3. (Zależne od algorytmu i iteracyjne) Algorytm na podstawie uzyskanej informacji o błędzie wprowadza poprawki do etapu szukania zależności i powtarza krok 1. i 2.\n",
    "\n",
    "Proces predykcji dla nowych danych - metoda `predict(X)`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![models_comparison](https://scikit-learn.org/stable/_images/sphx_glr_plot_classifier_comparison_001.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modele liniowe\n",
    "\n",
    "Zakładamy, że zmienną objaśnianą możemy wyrazić jako funkcję $f$ kombinacji liniowejzmiennych objaśnianych.\n",
    "\n",
    "$$ y_i = f(\\alpha + \\beta_1 x_{i1} + \\beta_2 x_{i2} + \\ldots + \\beta_p x_{ip}) $$\n",
    "\n",
    "W zapisie macierzowym $y = f(\\boldsymbol{\\beta} X  + \\alpha )$.\n",
    "\n",
    "Funkcja f może mieć różną postać najczęściej to f jest funkcją identycznościową albo funkcja logistyczna."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Regresja liniowa\n",
    "\n",
    "\n",
    "Wykorzystywana w problemach regresji, szczególnie tam gdzie nie ma nałożonych ograniczeń na wartość predykc\n",
    "\n",
    "$$ y_i = \\alpha + \\beta_1 x_{i1} + \\beta_2 x_{i2} + \\ldots + \\beta_p x_{ip} $$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "diabetes_one_col = pd.DataFrame(diabetes_X_train.iloc[:,2])\n",
    "plt.scatter(diabetes_one_col, diabetes_y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regr = LinearRegression(fit_intercept=True)\n",
    "regr.fit(diabetes_one_col, diabetes_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Coefficients: \\n', regr.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_diabetes_y = regr.predict(pd.DataFrame(diabetes_one_col))\n",
    "plt.hist(pred_diabetes_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(diabetes_one_col, diabetes_y,  color='black')\n",
    "plt.plot(diabetes_one_col, pred_diabetes_y, color='blue', linewidth=3)\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regresja dla większej liczby zmiennych"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regr_multi = LinearRegression()\n",
    "regr_multi.fit(diabetes_X_train, diabetes_y_train)\n",
    "print('Coeffifients:', regr_multi.coef_)\n",
    "print('Intercept:', regr_multi.intercept_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ridge i LASSO\n",
    "\n",
    "Zwykła regresja liniowa nie zależy od żadnych hiperparametrów wejściowych.\n",
    "\n",
    "Istnieją warianty regresji liniowej związane z regularyzacją (kontrolą wielkości współczynników) i selekcją zmiennych - [Ridge](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Ridge.html#sklearn.linear_model.Ridge) i [LASSO](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Lasso.html#sklearn.linear_model.Lasso). \n",
    "\n",
    "Ridge powoduje *ściąganie współczynników do zera* a LASSO *wybiera* zmienne.\n",
    "Moc regularyzacji zależy od hiperparametru `alpha`.\n",
    "\n",
    "\n",
    "Algorytm regresji liniowej [`ElasticNet`](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.ElasticNet.html#sklearn.linear_model.ElasticNet) \n",
    "jest kombinacją Ridge + LASSO i zależy od dwóch hiperparametrów `alpha` i `l1_ratio`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regresja logistyczna\n",
    "\n",
    "Najbardziej tradycyjne podejście do problemu klasyfikacji.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(breast_cancer_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jedną z motywacji jest to, że chcemy przewidzieć prawdopodobieństwo przynależności do klasy 1 zatem predykcja modelu powinna spełniać $0 \\leq f(x) \\leq 1$.\n",
    "\n",
    "Jednym z przykładów funkcji, która spełnia takie ograniczenie jest funkcja logistyczna\n",
    "$$ f(x) = \\frac{e^x}{1+e^x}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(-10, 11)\n",
    "y = 1/(1+np.exp(-x))\n",
    "plt.plot(x, y, '-')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "W algorytmie regresji logistycznej zakładamy,że prawdopodobieństwo przynależności do klasy `pozytywnej` jest funkcją logistyczną kombinacji liniowej zmiennych objaśniających.\n",
    "\n",
    "$$ \\hat{P}(Y=1|X=x) = \\frac{\\exp(\\alpha + \\beta_1 x_1 + \\beta_2 x_2 + \\ldots +  \\beta_p x_p )}{1+\\exp(\\alpha + \\beta_1 x_1 + \\beta_2 x_2 + \\ldots +  \\beta_p x_p )}$$\n",
    "\n",
    "$$ \\hat{P}(Y=0|X=x)= \\frac{1}{1+\\exp(\\alpha + \\beta'x)} $$\n",
    "\n",
    "W procesie trenowanie modelu obliczane są współczynniki: $\\beta = (\\beta_1, ..., \\beta_p)$ i $\\alpha$.\n",
    "\n",
    "\n",
    "W wyniku predykcji otrzymujemy prawdopodbieństwo klasy `pozytywnej` lub konkretną klasę jeśli ustalimy punkt odcięcia (threshold).\n",
    "\n",
    "Istnieją warianty Ridge, LASSO i ElasticNet zaszyte w hiperparametrze `penalty`. Hiperparametr `C` jest odpowiednikiem `alpha`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "?LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg = LogisticRegression(penalty = 'l2', max_iter = 200)\n",
    "log_reg.fit(cancer_X_train, cancer_y_train)\n",
    "log_reg.predict(cancer_X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg.predict_proba(cancer_X_test)[:10,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN- k najbliższych sąsiadów"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Przewidywanie klasy nowej obserwacji na podstawie $k$ najbliższych obserwacji z próby uczącej. Stosowana jest reguła większościowa.\n",
    "\n",
    "![](image/kknn_1.png)\n",
    "![](image/kknn_15.png)\n",
    "\n",
    "W różny sposób możemy określać odległość między obserwacjami (wybór metryki-`metric`), różną liczbę sąsiadów możemy brać pod uwagę."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "?KNeighborsClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_cf = KNeighborsClassifier()\n",
    "knn_cf.fit(cancer_X_train, cancer_y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_cf.predict(cancer_X_test)\n",
    "knn_cf.predict_proba(cancer_X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support vector machine (SVM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chcemy znaleźć najlepiej płaszczyznę najlepiej rozdzielającą obserwacje należące do różnych klas. Chcemy maksymalizować odległość obserwacji od tej płaszczyzny, a równocześnie każemy za popełnione błędy.\n",
    "\n",
    "![](image/svm_01.png)\n",
    "![](image/svm_02.png)\n",
    "\n",
    "Isnieje też rozszerzenie tej metody, w której dane  poddawane są przekształceniom zdefiniowanym przez hiperparametr `kernel`.\n",
    "\n",
    "\n",
    "Hiperparametry:\n",
    "* `kernel` - rodzaj przekształcenia, \n",
    "* `gamma` - dodatkowy parametr związany z przekształceniem zdefiniowanym przez `kernel`, \n",
    "* `C` - parametr kary za błędy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "?SVC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://miro.medium.com/max/3000/1*gtF6KeL7b9zNHd7pXtC1Nw.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drzewa decyzyjne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "decision_tree = DecisionTreeClassifier(max_depth=2)\n",
    "decision_tree.fit(cancer_X_train, cancer_y_train)\n",
    "\n",
    "plot_tree(decision_tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Jak tworzone jest drzewo decyzyjne?\n",
    "\n",
    "\n",
    "$m$ - rodzic, $m_L$ - lewe dziecko, $m_R$ - prawe dziecko \n",
    "\n",
    "$Q_m$ - miara różnorodności dla $m$ (Gini, entropia)\n",
    "\n",
    "$\\hat{p}_L$ - liczba obserwacji w węźle $m_L$ dzielona przez liczbę obserwacji w węźle $m$, analogicznie $\\hat{p}_R$\n",
    "\n",
    "$$ \\Delta Q_{m, m_L, m_R} = Q_m - (\\hat{p}_LQ_{m_L} + \\hat{p}_RQ_{m_R})$$\n",
    "\n",
    "Chcemy tak wybierać podziały, żeby maksymalizować $\\Delta Q_{m, m_L, m_R}$.\n",
    "\n",
    "Predykcja w ostatnim weźle (liściu) jest robiona na podstawie \n",
    "- reguły większościowej dla klasyfikacji\n",
    "- średnia dla regresji\n",
    "\n",
    "Hiperparametry:\n",
    "\n",
    "- na jakim poziomie skoćczyć dzielenie:\n",
    "    * `min_samples_split` - the minimum number of observations that must exist in a node in order for a split to be attempted\n",
    "    * `max_depth` - maksymalna głebokość drzewa\n",
    "    * `ccp_alpha` - parametr przycinania\n",
    "- na podstawie jakiego kryterium (gini lub information)\n",
    "- ile zmiennych brać pod uwagę przy szukaniu nowego podziału\n",
    "\n",
    "$T$ - drzewo\n",
    "$R(T)$ - frakcja obserwacji, które źle zaklasyfikowaliśmy\n",
    "$cp = \\alpha$\n",
    "$$ R_{\\alpha}(T) = R(T) + \\alpha |T| $$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "?DecisionTreeClassifier\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://scikit-learn.org/stable/_images/sphx_glr_plot_iris_dtc_001.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lasy losowe - random forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lasy losowe są przykładem komitetu klasyfikatorów. Polegają na niezależnym tworzeniu `n_estimators` drzew decyzyjnych. \n",
    "Z każdego drzewa decyzyjnego otrzymujemy predykcję. Ostateczna predykcja jest średnią wszystkich predykcji.\n",
    "\n",
    "Algorytm ten dziedziczy większość hiperparametrów po drzewach decyzyjnych.\n",
    "\n",
    "Las losowy może być budowany na całych dostępnych danych treningowych lub na wylosowanej podpróbie ze zwracaniem (`bootstrap=True`).\n",
    "\n",
    "![](https://www.kdnuggets.com/wp-content/uploads/rand-forest-2.jpg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
    "?RandomForestClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_cf = RandomForestClassifier()\n",
    "\n",
    "rf_cf.fit(cancer_X_train, cancer_y_train)\n",
    "predicted_proba_y_test_rf = rf_cf.predict_proba(cancer_X_test)\n",
    "predicted_class_y_test_rf = rf_cf.predict(cancer_X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient boosting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://miro.medium.com/max/3908/1*FoOt85zXNCaNFzpEj7ucuA.png)\n",
    "\n",
    "Gradient boosting jest przykładem modelu addytywnego, złożony jest z wielu nieskomplikowanych klasyfikatorów (*weak learners*), ale nie zbudowanych niezależnie tak jak w przypadku lasów losowych, tylko budowanych iteracyjnie na rezyduach z poprzedniego modelu.\n",
    "\n",
    "Gradient boosting o głębokości $k$ można zapisać jako:\n",
    "$$ D(X) = d_1(X) + d_2(X) + \\ldots + d_k(X)$$,\n",
    "gdzie dla $d_{1}(X)$ zmienną odpowiedzi jest zmienna objaśniana $y$, ale dla kolejnych modeli $d_i(X)$ zmienną objaśnianą są rezydua z poprzedniego modelu. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://media.geeksforgeeks.org/wp-content/uploads/20200721214745/gradientboosting.PNG)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hiperparametry:\n",
    "- `n_estimators` - liczba budowanych drzew\n",
    "- `learning_rate` - waga z jaką włączane są do ostatecznej predykcji, predykcje z kolejnych drzew\n",
    "- parametry związane z budową drzew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "?GradientBoostingClassifier\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**XGBoost**, **CatBoost**, **LightGBM**  to inne implementacje tego algorytmu. Różnią od GBM sposobem poszukiwania podziałów w drzewach.\n",
    "\n",
    "Nie są dostępne w sklearn. Trzeba zainstalować odpowiedni pakiet."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sieci neuronowe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div>\n",
    "<img src=\"https://scikit-learn.org/stable/_images/multilayerperceptron_network.png\" width=\"500\" style=\"float:middle\"/>\n",
    "</div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Warstwa $[x_1, x_2, \\ldots, x_n]$ to *wejście sieci neurnowej (input layer)* składa się z tylu neuronów ile zmiennych ma zbiór danych.\n",
    "\n",
    "Warstwa $[a_1, a_2, \\ldots, a_k]$ to *warstwa ukryta (hidden layer)*. Każdy neuron jest funkcją kombinacji liniowej z poprzedniej warstwy, w tym przypadku input layer.\n",
    "\n",
    "$$ a_1 = \\sigma(b_1 + w_{11} x_1 +  w_{21} x_2 + \\ldots + w_{n1} x_n)$$\n",
    "\n",
    "$w_{ij}$ to wagi sieci\n",
    "\n",
    "\n",
    "$\\sigma$ to funkcja aktywacji, musi być nieliniowa żeby sieć nie była po prostu regresją\n",
    "\n",
    "Najczęściej używane funkcje aktywacji: RELU, tanh, sigmoid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](http://rasbt.github.io/mlxtend/user_guide/classifier/NeuralNetMLP_files/neuralnet_mlp_1.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_clf = MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(5, 2), random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### F1\n",
    "\n",
    "Średnia harmoniczna precyzji i recall\n",
    "$$ F_1 = 2* \\frac{precision \\times recall}{precision + recall}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "f1_score(cancer_y_test,predicted_class_y_test_rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Miary oparte na predykcji prawdopodobieństwa\n",
    "\n",
    "#### Krzywa ROCR\n",
    "\n",
    "Ten wykres jest funkcją punktu odcięcia - jeśli model przewidzi prawdopodobieństwo powyżej tej wartości to klasyfikujemy ją do klasy pozytywnej. Dla punktów odcięcia wyznaczne jest False Positive Rate (x) vs. True Positive Rate (y).\n",
    "\n",
    "[Youtube](https://www.youtube.com/watch?v=4jRBRDbJemM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "fpr, tpr, thresholds = metrics.roc_curve(cancer_y_test, predicted_proba_y_test_rf[:,1], pos_label=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.plot_roc_curve(rf_cf, cancer_X_test, cancer_y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div>\n",
    "<img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/3/36/Roc-draft-xkcd-style.svg/1280px-Roc-draft-xkcd-style.svg.png\" width=\"500\" style=\"float:middle\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### AUC \n",
    "\n",
    "Pole pod krzywą ROC. AUC $\\in (0.5; 1]$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Krzywa Precision-Recall  i AUPR\n",
    "\n",
    "Krzywa PR : wykres Recall (x) vs Precision (y).  \n",
    "Oś Recall (True positive rate) taka sama jak przy krzywej ROC. W krzywej ROC jest True negative rate a w krzywe PR Precyzja.\n",
    "\n",
    "\n",
    "**AUPR** - pole pod tą krzywą, AUPR $\\in (0.5; 1]$.\n",
    "\n",
    "Ważne dla niezbalansowanych danych - obie miary precision i recall patrzą na mniej liczną klasę."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Klasyfikacja wieloetykietowa\n",
    "\n",
    "### Accuracy \n",
    "\n",
    "### Micro i Macro-average score\n",
    "\n",
    "Traktujemy każdą pojedynczą klasę $i$ jako pozytywną a pozostałe jako negatywne (One vs. All) i obliczamy dla niej metryki $TP_i, TN_i, FP_i, FN_i$.\n",
    "\n",
    "**Micro averaged precision** - modyfikujemy wzór na precyzję i jako $TP$ bierzemy sumę $TP_i$ dla wszystkich klas itd.\n",
    "\n",
    "$$ Precision_{micro}=  \\frac{TP_i +\\ldots +TP_k}{(TP_i +\\ldots +TP_k) +(FP_i +\\ldots +FP_k)} $$\n",
    "\n",
    "**Macro averaged precision** - średnia precyzji dla każdej klasy\n",
    "$$ Precision_i = \\frac{TP_i}{TP_i+FP_i} $$\n",
    "\n",
    "\n",
    "$$ Precision_{macro}=  \\frac{Precision_1 +\\ldots+Precision_k}{k} $$\n",
    "\n",
    "Analogicznie powstają pozostałe miary oparte o tablicę pomyłek, a potem $F1 score$, krzywa ROC i AUC.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Więcej materiałów i kod można znaleźć [tu](https://vitalflux.com/micro-average-macro-average-scoring-metrics-multi-class-classification-python/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem generalizacji"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Podział na zbiór testowy i treningowy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kroswalidacja\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Aby lepiej oceniać stabilność jakośni modeli na danych treningowych stosuje się kroswalidację - cały zbiór danych treningowy dzielimy na $k$ - podzbiorów. W każdej iteracji uczymy algorytm na $k-1$ podzbiorach a testujemy na pozostałym jednym zbiorze danych. \n",
    "\n",
    "Jako ocenę jakości modeli możemy stosować każdą z wyżej wymienionych miar.\n",
    "\n",
    "Jeśli model jest dobrze przygotowany to błąd, który uzyskamy na zbiorze testowym (który nie był wykorzystywany w kroswalidacji) powiniem być zbliżony do średnigo błędu z kroswalidacji.\n",
    "\n",
    "![](image/crossvalidation.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "# parametr cv  - możemy podać liczę podzialow, albo konkretny podzial po indeksach ramki danych \n",
    "# scoring - jakiej metryki uzyc do oceny\n",
    "\n",
    "rf_clf = RandomForestClassifier(n_estimators=10)\n",
    "\n",
    "\n",
    "cv_results = cross_validate(rf_clf, cancer_X_train, cancer_y_train, cv=3)\n",
    "print(cv_results.keys())\n",
    "\n",
    "print(cv_results['test_score'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mozemy podawac kilka metryk, ktore beda sprawdzane na zbiorze testowym i treningowym (scoring)\n",
    "# Mozemy zachowywac tez wyniki na zbiorze treningowym (return_train_score)\n",
    "\n",
    "cv_results = cross_validate(rf_clf, cancer_X_train, cancer_y_train, cv=3, \n",
    "                            return_train_score = True,scoring =  ['accuracy', 'roc_auc'])\n",
    "print(cv_results.keys())\n",
    "\n",
    "print(cv_results['test_accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ZADANIE\n",
    "\n",
    "Dla przedstawionych modeli podaj listę ich hiperparametrów."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelowy skrypt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## wczytanie bibliotek\n",
    "\n",
    "## wczytanie danych\n",
    "\n",
    "## zdefiniowanie zmiennej odpowiedzi i zmiennych objasniajacych\n",
    "\n",
    "## analiza eksploracyjna i preprocessing\n",
    "\n",
    "## podzial na zbior testowy i treningowy\n",
    "\n",
    "## wybor algorytmow i tuning hiperparametrow\n",
    "\n",
    "## porownanie najlepszych modeli pomiedzy algorytmami"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ZADANIE\n",
    "\n",
    "Na danych `train.csv` wytrenuj przynajmniej 5 różnych modeli i oceń ich jakość predykcji na zbiorze `test.csv`. \n",
    "a) Który model poradził sobie najlepiej?\n",
    "b) Dla najlepszego modelu spróbuj znaleźć wartość hiperparametrów, które poprawią jego jakość."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
